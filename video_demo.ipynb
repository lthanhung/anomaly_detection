{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulate a transistor product line video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculated background color: (90, 99, 140)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Thư mục chứa các ảnh\n",
    "image_folder = r\"D:\\anomaly_detection\\transistor_images\"\n",
    "# Lấy danh sách các ảnh trong thư mục\n",
    "images = [os.path.join(image_folder, f) for f in sorted(os.listdir(image_folder)) if f.endswith(('.png', '.jpg'))]\n",
    "\n",
    "# Hàm tính màu nền trung bình\n",
    "def calculate_background_color(image_path):\n",
    "    img = cv2.imread(image_path)\n",
    "    # Chọn vùng góc trên bên trái (hoặc có thể chọn biên khác)\n",
    "    corner_pixels = np.array([img[0, 0], img[0, -1], img[-1, 0], img[-1, -1]])\n",
    "    avg_color = np.mean(corner_pixels, axis=0)\n",
    "    return tuple(map(int, avg_color))\n",
    "\n",
    "# Tính màu nền trung bình từ các ảnh\n",
    "background_color = np.mean([calculate_background_color(img) for img in images], axis=0)\n",
    "background_color = tuple(map(int, background_color)) \n",
    "\n",
    "print(\"Calculated background color:\", background_color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video saved as transistor_productline.mp4\n"
     ]
    }
   ],
   "source": [
    "# import os\n",
    "# import cv2\n",
    "# import numpy as np\n",
    "\n",
    "# output_video = \"transistor_productline.mp4\"\n",
    "# image_folder = r\"D:\\anomaly_detection\\transistor_images\"\n",
    "# frame_size = (640, 640)\n",
    "# fps = 60\n",
    "# speed = 6\n",
    "# gap = 640\n",
    "# stop_duration = 4\n",
    "\n",
    "# images = [os.path.join(image_folder, f) for f in sorted(os.listdir(image_folder)) if f.endswith(('.png', '.jpg'))]\n",
    "# num_images = len(images)\n",
    "\n",
    "# background_color = (90, 99, 140)\n",
    "# frame = np.full((frame_size[1], frame_size[0], 3), background_color, dtype=np.uint8)\n",
    "\n",
    "# fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "# out = cv2.VideoWriter(output_video, fourcc, fps, frame_size)\n",
    "\n",
    "# resized_images = []\n",
    "# scale_factor = 0.25\n",
    "# for img_path in images:\n",
    "#     img = cv2.imread(img_path)\n",
    "#     new_height = int(img.shape[0] * scale_factor)\n",
    "#     new_width = int(img.shape[1] * scale_factor)\n",
    "#     resized_img = cv2.resize(img, (new_width, new_height))\n",
    "#     resized_images.append(resized_img)\n",
    "\n",
    "# img_height, img_width = resized_images[0].shape[:2]\n",
    "# total_width = num_images * (img_width + gap) - gap\n",
    "\n",
    "# for i, img in enumerate(resized_images):\n",
    "#     for x_offset in range(-img_width, frame_size[0] // 2 - img_width // 2 + 1, speed):\n",
    "#         frame = np.full((frame_size[1], frame_size[0], 3), background_color, dtype=np.uint8)\n",
    "#         y_pos = (frame_size[1] - img_height) // 2\n",
    "\n",
    "#         x_pos = x_offset\n",
    "\n",
    "#         if x_pos + img_width > 0 and x_pos < frame_size[0]:\n",
    "#             img_x_start = max(0, -x_pos)\n",
    "#             img_x_end = min(img_width, frame_size[0] - x_pos)\n",
    "#             frame_x_start = max(0, x_pos)\n",
    "#             frame_x_end = frame_x_start + (img_x_end - img_x_start)\n",
    "\n",
    "#             frame[y_pos:y_pos + img_height, frame_x_start:frame_x_end] = img[:, img_x_start:img_x_end]\n",
    "\n",
    "#         out.write(frame)\n",
    "\n",
    "#     frame = np.full((frame_size[1], frame_size[0], 3), background_color, dtype=np.uint8)\n",
    "#     y_pos = (frame_size[1] - img_height) // 2\n",
    "#     x_pos = frame_size[0] // 2 - img_width // 2\n",
    "#     frame[y_pos:y_pos + img_height, x_pos:x_pos + img_width] = img\n",
    "\n",
    "#     for _ in range(int(fps * stop_duration)):\n",
    "#         out.write(frame)\n",
    "\n",
    "#     for x_offset in range(frame_size[0] // 2 - img_width // 2, frame_size[0], speed):\n",
    "#         frame = np.full((frame_size[1], frame_size[0], 3), background_color, dtype=np.uint8)\n",
    "#         y_pos = (frame_size[1] - img_height) // 2\n",
    "\n",
    "#         x_pos = x_offset\n",
    "\n",
    "#         if x_pos + img_width > 0 and x_pos < frame_size[0]:\n",
    "#             img_x_start = max(0, -x_pos)\n",
    "#             img_x_end = min(img_width, frame_size[0] - x_pos)\n",
    "#             frame_x_start = max(0, x_pos)\n",
    "#             frame_x_end = frame_x_start + (img_x_end - img_x_start)\n",
    "\n",
    "#             frame[y_pos:y_pos + img_height, frame_x_start:frame_x_end] = img[:, img_x_start:img_x_end]\n",
    "\n",
    "#         out.write(frame)\n",
    "\n",
    "# out.release()\n",
    "# print(f\"Video saved as {output_video}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save frames from video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: frames\\frame_0.png\n",
      "Saved: frames\\frame_1.png\n",
      "Saved: frames\\frame_2.png\n",
      "Saved: frames\\frame_3.png\n",
      "Saved: frames\\frame_4.png\n",
      "Saved: frames\\frame_5.png\n",
      "Saved: frames\\frame_6.png\n",
      "Saved: frames\\frame_7.png\n",
      "Saved: frames\\frame_8.png\n",
      "Saved: frames\\frame_9.png\n",
      "Saved: frames\\frame_10.png\n",
      "Saved: frames\\frame_11.png\n",
      "Saved: frames\\frame_12.png\n",
      "Saved: frames\\frame_13.png\n",
      "Saved: frames\\frame_14.png\n",
      "Saved: frames\\frame_15.png\n",
      "Saved: frames\\frame_16.png\n",
      "Saved: frames\\frame_17.png\n",
      "Saved: frames\\frame_18.png\n",
      "Saved: frames\\frame_19.png\n",
      "Saved: frames\\frame_20.png\n",
      "Saved: frames\\frame_21.png\n",
      "Saved: frames\\frame_22.png\n",
      "Saved: frames\\frame_23.png\n",
      "Saved: frames\\frame_24.png\n",
      "Saved: frames\\frame_25.png\n",
      "Saved: frames\\frame_26.png\n",
      "Saved: frames\\frame_27.png\n",
      "Saved: frames\\frame_28.png\n",
      "Saved: frames\\frame_29.png\n",
      "Saved: frames\\frame_30.png\n",
      "Saved: frames\\frame_31.png\n",
      "Saved: frames\\frame_32.png\n",
      "Saved: frames\\frame_33.png\n",
      "Saved: frames\\frame_34.png\n",
      "Saved: frames\\frame_35.png\n",
      "Saved: frames\\frame_36.png\n",
      "Saved: frames\\frame_37.png\n",
      "Saved: frames\\frame_38.png\n",
      "Saved: frames\\frame_39.png\n",
      "Processing completed.\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "# Ensure the output directory exists\n",
    "output_dir = \"frames\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Video path\n",
    "video_path = r'D:\\anomaly_detection\\transistor_productline.mp4'\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Get video frame rate (frames per second)\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "# Calculate frame interval based on 1-second intervals\n",
    "#frame_interval = int(fps)  \n",
    "frame_id = 0\n",
    "start_time = 0.9\n",
    "frame_time = start_time  \n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Get the current time position of the video in seconds\n",
    "    current_time = cap.get(cv2.CAP_PROP_POS_MSEC) / 1000\n",
    "\n",
    "    # Save frame if the current time matches or exceeds the frame_time\n",
    "    if current_time >= frame_time:\n",
    "        output_path = os.path.join(output_dir, f\"frame_{frame_id}.png\")\n",
    "        cv2.imwrite(output_path, frame)\n",
    "        print(f\"Saved: {output_path}\")\n",
    "        \n",
    "        # Increment frame_time for the next interval\n",
    "        frame_time += 1.87\n",
    "        frame_id += 1\n",
    "\n",
    "cap.release()\n",
    "print(\"Processing completed.\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detect transistors from frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 5 main_boards, 24.0ms\n",
      "Speed: 4.0ms preprocess, 24.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Saved: yolov11_outputs\\frame_0.png\n",
      "\n",
      "0: 640x640 4 main_boards, 24.0ms\n",
      "Speed: 3.0ms preprocess, 24.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Saved: yolov11_outputs\\frame_1.png\n",
      "\n",
      "0: 640x640 5 main_boards, 24.0ms\n",
      "Speed: 3.0ms preprocess, 24.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Saved: yolov11_outputs\\frame_10.png\n",
      "\n",
      "0: 640x640 4 main_boards, 24.0ms\n",
      "Speed: 3.0ms preprocess, 24.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Saved: yolov11_outputs\\frame_11.png\n",
      "\n",
      "0: 640x640 4 main_boards, 23.0ms\n",
      "Speed: 3.0ms preprocess, 23.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Saved: yolov11_outputs\\frame_12.png\n",
      "\n",
      "0: 640x640 4 main_boards, 17.0ms\n",
      "Speed: 3.0ms preprocess, 17.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Saved: yolov11_outputs\\frame_13.png\n",
      "\n",
      "0: 640x640 5 main_boards, 16.0ms\n",
      "Speed: 3.0ms preprocess, 16.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Saved: yolov11_outputs\\frame_14.png\n",
      "\n",
      "0: 640x640 4 main_boards, 16.4ms\n",
      "Speed: 4.0ms preprocess, 16.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Saved: yolov11_outputs\\frame_2.png\n",
      "\n",
      "0: 640x640 4 main_boards, 16.3ms\n",
      "Speed: 3.2ms preprocess, 16.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Saved: yolov11_outputs\\frame_3.png\n",
      "\n",
      "0: 640x640 4 main_boards, 16.7ms\n",
      "Speed: 3.0ms preprocess, 16.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Saved: yolov11_outputs\\frame_4.png\n",
      "\n",
      "0: 640x640 4 main_boards, 16.0ms\n",
      "Speed: 3.0ms preprocess, 16.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Saved: yolov11_outputs\\frame_5.png\n",
      "\n",
      "0: 640x640 4 main_boards, 10.0ms\n",
      "Speed: 4.0ms preprocess, 10.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Saved: yolov11_outputs\\frame_6.png\n",
      "\n",
      "0: 640x640 4 main_boards, 10.0ms\n",
      "Speed: 2.0ms preprocess, 10.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Saved: yolov11_outputs\\frame_7.png\n",
      "\n",
      "0: 640x640 4 main_boards, 10.0ms\n",
      "Speed: 3.0ms preprocess, 10.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Saved: yolov11_outputs\\frame_8.png\n",
      "\n",
      "0: 640x640 4 main_boards, 10.0ms\n",
      "Speed: 2.0ms preprocess, 10.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Saved: yolov11_outputs\\frame_9.png\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "import cv2\n",
    "import os\n",
    "from ultralytics import YOLO\n",
    "\n",
    "yolov11_model = YOLO(r\"D:\\anomaly_detection\\runs\\detect\\yolo11-mainboard7\\weights\\best.pt\")\n",
    "input_dir = r\"D:\\anomaly_detection\\frames\"\n",
    "output_dir = \"yolov11_outputs\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "for filename in os.listdir(input_dir):\n",
    "    if filename.endswith(\".png\") or filename.endswith(\".jpg\"):\n",
    "        img_path = os.path.join(input_dir, filename)\n",
    "        image = cv2.imread(img_path)\n",
    "        \n",
    "        results = yolov11_model(image)\n",
    "        base_name = os.path.splitext(os.path.basename(filename))[0]\n",
    "        \n",
    "        for result in results:\n",
    "            boxes = result.boxes.cpu().numpy() \n",
    "            class_ids = result.boxes.cls.cpu().numpy() \n",
    "\n",
    "            for i in range(len(boxes)):\n",
    "                box = boxes[i]\n",
    "                class_id = int(class_ids[i])\n",
    "\n",
    "                if class_id == 0:  \n",
    "                    x_min, y_min, x_max, y_max = box.xyxy[0]\n",
    "                    x_min, y_min, x_max, y_max = map(int, [x_min, y_min, x_max, y_max])\n",
    "                    \n",
    "                    # Calculate the width and height of the bounding box\n",
    "                    width = x_max - x_min\n",
    "                    height = y_max - y_min\n",
    "\n",
    "                    # Only resize if the width and height are between 240 and 270\n",
    "                    if 246 <= width <= 266 and 246 <= height <= 266:\n",
    "                        # Extract the region of interest (ROI)\n",
    "                        roi = image[y_min:y_max, x_min:x_max]\n",
    "\n",
    "                        # Resize the ROI to 256x256\n",
    "                        resized_roi = cv2.resize(roi, (256, 256))\n",
    "\n",
    "                        # Save the resized image\n",
    "                        output_path = os.path.join(output_dir, f\"{base_name}.png\")\n",
    "                        cv2.imwrite(output_path, resized_roi)\n",
    "                        print(f\"Saved: {output_path}\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PaDiM detect anomaly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transistor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 0_normal.png - Anomaly Score: 0.6425\n",
      "Processed 1_damaged_case.png - Anomaly Score: 0.7119\n",
      "Processed 2_cut_lead.png - Anomaly Score: 0.7081\n",
      "Processed 3_misplaced.png - Anomaly Score: 0.9622\n",
      "Processed 4_bent_lead.png - Anomaly Score: 1.0000\n",
      "Processed 5_cut_lead.png - Anomaly Score: 0.6356\n",
      "Processed 6_damaged_case.png - Anomaly Score: 0.8853\n",
      "Processed 7_bent_lead.png - Anomaly Score: 0.9231\n",
      "Processed 8_normal.png - Anomaly Score: 0.7011\n",
      "Processed 9_misplaced.png - Anomaly Score: 1.0000\n",
      "Processing completed.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from anomalib.deploy import OpenVINOInferencer\n",
    "from pathlib import Path\n",
    "from PIL import ImageFont, ImageDraw, Image\n",
    "\n",
    "openvino_model_path = Path(\"D:/anomaly_detection/results/Padim/transistor/latest/weights/openvino/model.bin\")\n",
    "metadata_path = Path(\"D:/anomaly_detection/results/Padim/transistor/latest/weights/openvino/metadata.json\")\n",
    "inferencer = OpenVINOInferencer(path=openvino_model_path, metadata=metadata_path, device=\"GPU\")\n",
    "\n",
    "input_dir = r\"D:\\anomaly_detection\\transistor_images\"\n",
    "output_dir = \"anomaly_detection_results\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "def draw_text_with_pillow(frame, text, position, font_path=\"arialbd.ttf\", font_size=48):\n",
    "    pil_img = Image.fromarray(frame)\n",
    "    draw = ImageDraw.Draw(pil_img)\n",
    "    font = ImageFont.truetype(font_path, font_size)  # Dùng font đậm và kích thước lớn hơn\n",
    "    draw.text(position, text, font=font, fill=(255, 255, 255))  # Màu chữ trắng\n",
    "    return np.array(pil_img)\n",
    "\n",
    "for filename in os.listdir(input_dir):\n",
    "    input_path = os.path.join(input_dir, filename)\n",
    "    image = cv2.imread(input_path)\n",
    "    if image is None:\n",
    "        continue\n",
    "\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    result = inferencer.predict(image)\n",
    "    anomaly_map = result.anomaly_map\n",
    "\n",
    "    anomaly_map_normalized = cv2.normalize(anomaly_map, None, 0, 1, cv2.NORM_MINMAX)\n",
    "\n",
    "    heatmap = np.zeros_like(image)\n",
    "    heatmap[:, :, 2] = (anomaly_map_normalized * 255).astype(np.uint8)\n",
    "\n",
    "    heatmap = cv2.GaussianBlur(heatmap, (21, 21), 0)\n",
    "\n",
    "    mask = anomaly_map_normalized > 0.25\n",
    "    heatmap[~mask] = 0\n",
    "\n",
    "    heatmap_weighted = cv2.addWeighted(image, 1, heatmap, 0.6, 0)\n",
    "\n",
    "    name = filename[2:-4]\n",
    "    name_translation = {\n",
    "        \"normal\": \"Bình thường\",\n",
    "        \"bent_lead\": \"Dây dẫn bị cong\",\n",
    "        \"cut_lead\": \"Dây dẫn bị cắt\",\n",
    "        \"misplaced\": \"Đặt sai vị trí\",\n",
    "        \"damaged_case\": \"Vỏ bị hỏng\"\n",
    "    }\n",
    "    translated_name = name_translation.get(name, name)\n",
    "\n",
    "    text = f\"Kết quả: {translated_name}\"\n",
    "    heatmap_weighted = draw_text_with_pillow(heatmap_weighted, text, (10, 30))\n",
    "\n",
    "    output_image = cv2.cvtColor(heatmap_weighted, cv2.COLOR_RGB2BGR)\n",
    "    output_path = os.path.join(output_dir, f\"{Path(filename).stem}_result.png\")\n",
    "    cv2.imwrite(output_path, output_image)\n",
    "\n",
    "    print(f\"Processed {filename} - Anomaly Score: {result.pred_score:.4f}\")\n",
    "\n",
    "print(\"Processing completed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 0_normal.png - Anomaly Score: 1.0000\n",
      "Processed 1_cut_outer_insulation.png - Anomaly Score: 1.0000\n",
      "Processed 2_missing_wire.png - Anomaly Score: 0.8796\n",
      "Processed 3_cable_swap.png - Anomaly Score: 0.9347\n",
      "Processed 4_bent_wire.png - Anomaly Score: 1.0000\n",
      "Processed 5_cut_inner_insulation.png - Anomaly Score: 0.9235\n",
      "Processed 6_poke_insulation.png - Anomaly Score: 1.0000\n",
      "Processed 7_normal.png - Anomaly Score: 0.8087\n",
      "Processed 8_combined.png - Anomaly Score: 0.9415\n",
      "Processed 9_missing_cable.png - Anomaly Score: 0.8697\n",
      "Processing completed.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from anomalib.deploy import OpenVINOInferencer\n",
    "from pathlib import Path\n",
    "from PIL import ImageFont, ImageDraw, Image\n",
    "\n",
    "openvino_model_path = Path(\"D:/anomaly_detection/results/Padim/cable/latest/weights/openvino/model.bin\")\n",
    "metadata_path = Path(\"D:/anomaly_detection/results/Padim/cable/latest/weights/openvino/metadata.json\")\n",
    "inferencer = OpenVINOInferencer(path=openvino_model_path, metadata=metadata_path, device=\"GPU\")\n",
    "\n",
    "input_dir = r\"D:\\anomaly_detection\\cable_images\"\n",
    "output_dir = \"cable_anomaly_detection_results\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "def draw_text_with_pillow(frame, text, position, font_path=\"arialbd.ttf\", font_size=48):\n",
    "    pil_img = Image.fromarray(frame)\n",
    "    draw = ImageDraw.Draw(pil_img)\n",
    "    font = ImageFont.truetype(font_path, font_size)  # Dùng font đậm và kích thước lớn hơn\n",
    "    draw.text(position, text, font=font, fill=(255, 255, 255))  # Màu chữ trắng\n",
    "    return np.array(pil_img)\n",
    "\n",
    "for filename in os.listdir(input_dir):\n",
    "    input_path = os.path.join(input_dir, filename)\n",
    "    image = cv2.imread(input_path)\n",
    "    if image is None:\n",
    "        continue\n",
    "\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    result = inferencer.predict(image)\n",
    "    anomaly_map = result.anomaly_map\n",
    "\n",
    "    anomaly_map_normalized = cv2.normalize(anomaly_map, None, 0, 1, cv2.NORM_MINMAX)\n",
    "\n",
    "    heatmap = np.zeros_like(image)\n",
    "    heatmap[:, :, 2] = (anomaly_map_normalized * 255).astype(np.uint8)\n",
    "\n",
    "    heatmap = cv2.GaussianBlur(heatmap, (21, 21), 0)\n",
    "\n",
    "    mask = anomaly_map_normalized > 0.25\n",
    "    heatmap[~mask] = 0\n",
    "\n",
    "    heatmap_weighted = cv2.addWeighted(image, 1, heatmap, 0.6, 0)\n",
    "\n",
    "    name = filename[2:-4]\n",
    "    name_translation = {\n",
    "    \"bent_wire\": \"Dây bị cong\",\n",
    "    \"cut_inner_insulation\": \"Lớp cách điện trong bị cắt\",\n",
    "    \"missing_cable\": \"Thiếu cáp\",\n",
    "    \"combined\": \"Nhiều lỗi\",\n",
    "    \"cable_swap\": \"Nhầm cáp\",\n",
    "    \"missing_wire\": \"Thiếu dây\",\n",
    "    \"poke_insulation\": \"Thủng lớp cách điện\",\n",
    "    \"normal\": \"Bình thường\",\n",
    "    \"cut_outer_insulation\": \"Lớp cách điện ngoài bị cắt\"\n",
    "}\n",
    "    translated_name = name_translation.get(name, name)\n",
    "\n",
    "    text = f\"Kết quả: {translated_name}\"\n",
    "    heatmap_weighted = draw_text_with_pillow(heatmap_weighted, text, (10, 30))\n",
    "\n",
    "    output_image = cv2.cvtColor(heatmap_weighted, cv2.COLOR_RGB2BGR)\n",
    "    output_path = os.path.join(output_dir, f\"{Path(filename).stem}_result.png\")\n",
    "    cv2.imwrite(output_path, output_image)\n",
    "\n",
    "    print(f\"Processed {filename} - Anomaly Score: {result.pred_score:.4f}\")\n",
    "\n",
    "print(\"Processing completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 0_normal.png - Anomaly Score: 1.0000\n",
      "Processed 1_cut_outer_insulation.png - Anomaly Score: 1.0000\n",
      "Processed 2_bent_wire.png - Anomaly Score: 1.0000\n",
      "Processed 3_poke_insulation.png - Anomaly Score: 1.0000\n",
      "Processed 4_cable_swap.png - Anomaly Score: 0.9347\n",
      "Processed 5_cut_inner_insulation.png - Anomaly Score: 0.9235\n",
      "Processed 6_missing_wire.png - Anomaly Score: 0.8845\n",
      "Processed 7_normal.png - Anomaly Score: 0.8087\n",
      "Processed 8_combined.png - Anomaly Score: 0.9415\n",
      "Processed 9_missing_cable.png - Anomaly Score: 0.8697\n",
      "Processing completed.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from anomalib.deploy import OpenVINOInferencer\n",
    "from pathlib import Path\n",
    "from PIL import ImageFont, ImageDraw, Image\n",
    "\n",
    "openvino_model_path = Path(\"D:/anomaly_detection/results/Padim/cable/latest/weights/openvino/model.bin\")\n",
    "metadata_path = Path(\"D:/anomaly_detection/results/Padim/cable/latest/weights/openvino/metadata.json\")\n",
    "inferencer = OpenVINOInferencer(path=openvino_model_path, metadata=metadata_path, device=\"GPU\")\n",
    "\n",
    "input_dir = r\"D:\\anomaly_detection\\cable_images\"\n",
    "output_dir = \"cable_anomaly_detection_results\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "def draw_text_with_pillow(frame, text, position, font_path=\"arialbd.ttf\", font_size=48):\n",
    "    pil_img = Image.fromarray(frame)\n",
    "    draw = ImageDraw.Draw(pil_img)\n",
    "    font = ImageFont.truetype(font_path, font_size)  # Dùng font đậm và kích thước lớn hơn\n",
    "    draw.text(position, text, font=font, fill=(255, 255, 255))  # Màu chữ trắng\n",
    "    return np.array(pil_img)\n",
    "\n",
    "for filename in os.listdir(input_dir):\n",
    "    input_path = os.path.join(input_dir, filename)\n",
    "    image = cv2.imread(input_path)\n",
    "    if image is None:\n",
    "        continue\n",
    "\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    result = inferencer.predict(image)\n",
    "    anomaly_map = result.anomaly_map\n",
    "\n",
    "    anomaly_map_normalized = cv2.normalize(anomaly_map, None, 0, 1, cv2.NORM_MINMAX)\n",
    "\n",
    "    heatmap = np.zeros_like(image)\n",
    "\n",
    "    # Tạo vùng vàng (kết hợp đỏ và xanh lá cho các vùng bất thường)\n",
    "    heatmap[:, :, 2] = (anomaly_map_normalized * 255).astype(np.uint8)  # Màu đỏ\n",
    "    heatmap[:, :, 1] = (anomaly_map_normalized * 255).astype(np.uint8)  # Màu xanh lá\n",
    "\n",
    "    # Áp dụng Gaussian Blur để mượt mà\n",
    "    heatmap = cv2.GaussianBlur(heatmap, (21, 21), 0)\n",
    "\n",
    "    # Tạo mask và chỉ làm vàng cho các vùng bất thường\n",
    "    mask = anomaly_map_normalized > 0.25\n",
    "    heatmap[mask] = [0, 255, 255]  # Màu vàng cho các vùng mask (Red + Green)\n",
    "\n",
    "    # Kết hợp heatmap vào ảnh gốc\n",
    "    heatmap_weighted = cv2.addWeighted(image, 1, heatmap, 0.6, 0)\n",
    "\n",
    "    name = filename[2:-4]\n",
    "    name_translation = {\n",
    "    \"bent_wire\": \"Dây bị cong\",\n",
    "    \"cut_inner_insulation\": \"Lớp cách điện trong bị cắt\",\n",
    "    \"missing_cable\": \"Thiếu cáp\",\n",
    "    \"combined\": \"Nhiều lỗi\",\n",
    "    \"cable_swap\": \"Nhầm cáp\",\n",
    "    \"missing_wire\": \"Thiếu dây\",\n",
    "    \"poke_insulation\": \"Thủng lớp cách điện\",\n",
    "    \"normal\": \"Bình thường\",\n",
    "    \"cut_outer_insulation\": \"Lớp cách điện ngoài bị cắt\"\n",
    "}\n",
    "    translated_name = name_translation.get(name, name)\n",
    "\n",
    "    text = f\"Kết quả: {translated_name}\"\n",
    "    heatmap_weighted = draw_text_with_pillow(heatmap_weighted, text, (10, 30))\n",
    "\n",
    "    output_image = cv2.cvtColor(heatmap_weighted, cv2.COLOR_RGB2BGR)\n",
    "    output_path = os.path.join(output_dir, f\"{Path(filename).stem}_result.png\")\n",
    "    cv2.imwrite(output_path, output_image)\n",
    "\n",
    "    print(f\"Processed {filename} - Anomaly Score: {result.pred_score:.4f}\")\n",
    "\n",
    "print(\"Processing completed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate final result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Transistor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video saved as transistor_productline_result.mp4\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "output_video = \"transistor_productline_result.mp4\"\n",
    "image_folder = r\"D:\\anomaly_detection\\transistor_images\"\n",
    "image_result_folder = r\"D:\\anomaly_detection\\anomaly_detection_results\"\n",
    "frame_size = (640, 640)\n",
    "fps = 60\n",
    "speed = 6\n",
    "gap = 640\n",
    "stop_duration = 2\n",
    "\n",
    "images = [os.path.join(image_folder, f) for f in sorted(os.listdir(image_folder)) if f.endswith(('.png', '.jpg'))]\n",
    "num_images = len(images)\n",
    "\n",
    "background_color = (90, 99, 140)\n",
    "frame = np.full((frame_size[1], frame_size[0], 3), background_color, dtype=np.uint8)\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter(output_video, fourcc, fps, frame_size)\n",
    "\n",
    "resized_images = []\n",
    "scale_factor = 0.25\n",
    "for img_path in images:\n",
    "    img = cv2.imread(img_path)\n",
    "    new_height = int(img.shape[0] * scale_factor)\n",
    "    new_width = int(img.shape[1] * scale_factor)\n",
    "    resized_img = cv2.resize(img, (new_width, new_height))\n",
    "    resized_images.append(resized_img)\n",
    "\n",
    "img_height, img_width = resized_images[0].shape[:2]\n",
    "total_width = num_images * (img_width + gap) - gap\n",
    "\n",
    "for i, img in enumerate(resized_images):\n",
    "    # Move the original image across the screen\n",
    "    for x_offset in range(-img_width, frame_size[0] // 2 - img_width // 2 + 1, speed):\n",
    "        frame = np.full((frame_size[1], frame_size[0], 3), background_color, dtype=np.uint8)\n",
    "        y_pos = (frame_size[1] - img_height) // 2\n",
    "\n",
    "        x_pos = x_offset\n",
    "\n",
    "        if x_pos + img_width > 0 and x_pos < frame_size[0]:\n",
    "            img_x_start = max(0, -x_pos)\n",
    "            img_x_end = min(img_width, frame_size[0] - x_pos)\n",
    "            frame_x_start = max(0, x_pos)\n",
    "            frame_x_end = frame_x_start + (img_x_end - img_x_start)\n",
    "\n",
    "            frame[y_pos:y_pos + img_height, frame_x_start:frame_x_end] = img[:, img_x_start:img_x_end]\n",
    "\n",
    "        out.write(frame)\n",
    "\n",
    "    # Show the original image in the center for 1 second (stop_duration)\n",
    "    frame = np.full((frame_size[1], frame_size[0], 3), background_color, dtype=np.uint8)\n",
    "    y_pos = (frame_size[1] - img_height) // 2\n",
    "    x_pos = frame_size[0] // 2 - img_width // 2\n",
    "    frame[y_pos:y_pos + img_height, x_pos:x_pos + img_width] = img\n",
    "\n",
    "    for _ in range(int(fps * 1.5)):  \n",
    "        out.write(frame)\n",
    "\n",
    "    # Load and display the result image (mask) after the original image stops\n",
    "    result_img_path = os.path.join(image_result_folder, os.path.splitext(os.path.basename(images[i]))[0] + '_result' + os.path.splitext(images[i])[1])\n",
    "    result_img = cv2.imread(result_img_path)\n",
    "\n",
    "    if result_img is not None:\n",
    "        result_resized = cv2.resize(result_img, (new_width, new_height))\n",
    "\n",
    "        # Display the result image for stop_duration (after the original image stop)\n",
    "        for _ in range(int(fps * stop_duration)):\n",
    "            frame = np.full((frame_size[1], frame_size[0], 3), background_color, dtype=np.uint8)\n",
    "            y_pos = (frame_size[1] - img_height) // 2\n",
    "            x_pos = frame_size[0] // 2 - img_width // 2\n",
    "            frame[y_pos:y_pos + img_height, x_pos:x_pos + img_width] = result_resized\n",
    "            out.write(frame)\n",
    "\n",
    "        # Continue moving the result image across the screen\n",
    "        for x_offset in range(frame_size[0] // 2 - img_width // 2, frame_size[0], speed):\n",
    "            frame = np.full((frame_size[1], frame_size[0], 3), background_color, dtype=np.uint8)\n",
    "            y_pos = (frame_size[1] - img_height) // 2\n",
    "\n",
    "            x_pos = x_offset\n",
    "\n",
    "            if x_pos + img_width > 0 and x_pos < frame_size[0]:\n",
    "                img_x_start = max(0, -x_pos)\n",
    "                img_x_end = min(img_width, frame_size[0] - x_pos)\n",
    "                frame_x_start = max(0, x_pos)\n",
    "                frame_x_end = frame_x_start + (img_x_end - img_x_start)\n",
    "\n",
    "                frame[y_pos:y_pos + img_height, frame_x_start:frame_x_end] = result_resized[:, img_x_start:img_x_end]\n",
    "\n",
    "            out.write(frame)\n",
    "\n",
    "    else:\n",
    "        print(f\"Result image not found for {os.path.basename(images[i])}\")\n",
    "\n",
    "out.release()\n",
    "print(f\"Video saved as {output_video}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "output_video = \"transistor_productline_result.mp4\"\n",
    "image_folder = r\"D:\\anomaly_detection\\transistor_images\"\n",
    "image_result_folder = r\"D:\\anomaly_detection\\anomaly_detection_results\"\n",
    "frame_size = (640, 640)\n",
    "fps = 60\n",
    "speed = 6\n",
    "gap = 640\n",
    "stop_duration = 2\n",
    "\n",
    "images = [os.path.join(image_folder, f) for f in sorted(os.listdir(image_folder)) if f.endswith(('.png', '.jpg'))]\n",
    "num_images = len(images)\n",
    "\n",
    "background_color = (90, 99, 140)\n",
    "frame = np.full((frame_size[1], frame_size[0], 3), background_color, dtype=np.uint8)\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter(output_video, fourcc, fps, frame_size)\n",
    "\n",
    "resized_images = []\n",
    "scale_factor = 0.25\n",
    "for img_path in images:\n",
    "    img = cv2.imread(img_path)\n",
    "    new_height = int(img.shape[0] * scale_factor)\n",
    "    new_width = int(img.shape[1] * scale_factor)\n",
    "    resized_img = cv2.resize(img, (new_width, new_height))\n",
    "    resized_images.append(resized_img)\n",
    "\n",
    "img_height, img_width = resized_images[0].shape[:2]\n",
    "total_width = num_images * (img_width + gap) - gap\n",
    "\n",
    "for i, img in enumerate(resized_images):\n",
    "    # Move the original image across the screen\n",
    "    for x_offset in range(-img_width, frame_size[0] // 2 - img_width // 2 + 1, speed):\n",
    "        frame = np.full((frame_size[1], frame_size[0], 3), background_color, dtype=np.uint8)\n",
    "        y_pos = (frame_size[1] - img_height) // 2\n",
    "\n",
    "        x_pos = x_offset\n",
    "\n",
    "        if x_pos + img_width > 0 and x_pos < frame_size[0]:\n",
    "            img_x_start = max(0, -x_pos)\n",
    "            img_x_end = min(img_width, frame_size[0] - x_pos)\n",
    "            frame_x_start = max(0, x_pos)\n",
    "            frame_x_end = frame_x_start + (img_x_end - img_x_start)\n",
    "\n",
    "            frame[y_pos:y_pos + img_height, frame_x_start:frame_x_end] = img[:, img_x_start:img_x_end]\n",
    "\n",
    "        out.write(frame)\n",
    "\n",
    "    # Show the original image in the center for 1 second (stop_duration)\n",
    "    frame = np.full((frame_size[1], frame_size[0], 3), background_color, dtype=np.uint8)\n",
    "    y_pos = (frame_size[1] - img_height) // 2\n",
    "    x_pos = frame_size[0] // 2 - img_width // 2\n",
    "    frame[y_pos:y_pos + img_height, x_pos:x_pos + img_width] = img\n",
    "\n",
    "    for _ in range(int(fps * 1.5)):  \n",
    "        out.write(frame)\n",
    "\n",
    "    # Load and display the result image (mask) after the original image stops\n",
    "    result_img_path = os.path.join(image_result_folder, os.path.splitext(os.path.basename(images[i]))[0] + '_result' + os.path.splitext(images[i])[1])\n",
    "    result_img = cv2.imread(result_img_path)\n",
    "\n",
    "    if result_img is not None:\n",
    "        result_resized = cv2.resize(result_img, (new_width, new_height))\n",
    "\n",
    "        # Display the result image for stop_duration (after the original image stop)\n",
    "        for _ in range(int(fps * stop_duration)):\n",
    "            frame = np.full((frame_size[1], frame_size[0], 3), background_color, dtype=np.uint8)\n",
    "            y_pos = (frame_size[1] - img_height) // 2\n",
    "            x_pos = frame_size[0] // 2 - img_width // 2\n",
    "            frame[y_pos:y_pos + img_height, x_pos:x_pos + img_width] = result_resized\n",
    "            out.write(frame)\n",
    "\n",
    "        # Continue moving the result image across the screen\n",
    "        for x_offset in range(frame_size[0] // 2 - img_width // 2, frame_size[0], speed):\n",
    "            frame = np.full((frame_size[1], frame_size[0], 3), background_color, dtype=np.uint8)\n",
    "            y_pos = (frame_size[1] - img_height) // 2\n",
    "\n",
    "            x_pos = x_offset\n",
    "\n",
    "            if x_pos + img_width > 0 and x_pos < frame_size[0]:\n",
    "                img_x_start = max(0, -x_pos)\n",
    "                img_x_end = min(img_width, frame_size[0] - x_pos)\n",
    "                frame_x_start = max(0, x_pos)\n",
    "                frame_x_end = frame_x_start + (img_x_end - img_x_start)\n",
    "\n",
    "                frame[y_pos:y_pos + img_height, frame_x_start:frame_x_end] = result_resized[:, img_x_start:img_x_end]\n",
    "\n",
    "            out.write(frame)\n",
    "\n",
    "    else:\n",
    "        print(f\"Result image not found for {os.path.basename(images[i])}\")\n",
    "\n",
    "out.release()\n",
    "print(f\"Video saved as {output_video}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anomalib_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
